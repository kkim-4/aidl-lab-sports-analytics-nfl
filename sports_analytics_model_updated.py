# -*- coding: utf-8 -*-
"""Sports_Analytics_model_Updated.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13c5_-ixczUlcmy85EfeKEWsYsvrUXYrV
"""

import pandas as pd
import numpy as np
import tensorflow as tf
import os, random
from google.colab import drive
from tensorflow.keras import layers, models, regularizers, backend as K
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
import matplotlib.pyplot as plt
import seaborn as sns

# Set seeds for reproducibility
def set_seeds(seed=42):
    os.environ['PYTHONHASHSEED'] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)

set_seeds(42)
drive.mount('/content/drive')

def build_hybrid_tensors(df):
    df = df.copy()
    # 1. Standardize Direction & Physics
    df['X_std'] = np.where(df['PlayDirection'] == 'left', 120 - df['X'], df['X'])
    df['Y_std'] = np.where(df['PlayDirection'] == 'left', 53.3 - df['Y'], df['Y'])
    df['Dir_rad'] = np.mod(90 - df['Dir'], 360) * np.pi / 180.0
    df['Vx'] = df['S'] * np.cos(df['Dir_rad'])
    df['Vy'] = df['S'] * np.sin(df['Dir_rad'])
    df['IsExplosive'] = (df['Yards'] >= 10).astype(int)

    X_spatial, X_context, Y, meta = [], [], [], []
    play_ids = df['PlayId'].unique()

    for pid in play_ids:
        play_data = df[df['PlayId'] == pid].copy()
        rusher = play_data[play_data['NflId'] == play_data['NflIdRusher']]
        if len(play_data) != 22 or rusher.empty: continue

        r_x, r_y = rusher['X_std'].values[0], rusher['Y_std'].values[0]
        r_vx, r_vy = rusher['Vx'].values[0], rusher['Vy'].values[0]

        # Branch A: Spatial (RelX, RelY, RelVx, RelVy, S)
        play_data['RelX'] = (play_data['X_std'] - r_x) / 10.0
        play_data['RelY'] = (play_data['Y_std'] - r_y) / 5.0
        play_data['RelVx'] = (play_data['Vx'] - r_vx) / 5.0
        play_data['RelVy'] = (play_data['Vy'] - r_vy) / 5.0

        f_cols = ['RelX', 'RelY', 'RelVx', 'RelVy', 'S']
        spatial_matrix = np.vstack([
            play_data[play_data['NflId'] == rusher['NflId'].values[0]][f_cols].values,
            play_data[(play_data['Team'] == rusher['Team'].values[0]) & (play_data['NflId'] != rusher['NflId'].values[0])][f_cols].values,
            play_data[play_data['Team'] != rusher['Team'].values[0]][f_cols].values
        ])

        # Branch B: Context
        score_diff = rusher['HomeScoreBeforePlay'].values[0] - rusher['VisitorScoreBeforePlay'].values[0]
        context_vec = [
            rusher['Distance'].values[0], rusher['YardLine'].values[0],
            rusher['DefendersInTheBox'].values[0], score_diff, rusher['A'].values[0]
        ]

        X_spatial.append(spatial_matrix)
        X_context.append(context_vec)
        Y.append(play_data['IsExplosive'].iloc[0])
        meta.append([rusher['NflId'].values[0], rusher['DisplayName'].values[0]])

    return np.array(X_spatial), np.array(X_context), np.array(Y), np.array(meta)

class AxialBlock(layers.Layer):
    def __init__(self, d_model, num_heads):
        super().__init__()
        self.mha = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model // num_heads)
        self.ffn = models.Sequential([
            layers.Dense(d_model * 4, activation='gelu'),
            layers.Dense(d_model)
        ])
        self.ln1 = layers.LayerNormalization()
        self.ln2 = layers.LayerNormalization()

    def call(self, x, training=False):
        x = self.ln1(x + self.mha(x, x, training=training))
        x = self.ln2(x + self.ffn(x, training=training))
        return x

def build_hybrid_model(spatial_shape=(22, 5), context_dim=5):
    K.clear_session()
    # Spatial Branch
    s_in = layers.Input(shape=spatial_shape)
    x = layers.Dense(64, activation='gelu')(s_in)
    for _ in range(3): x = AxialBlock(64, num_heads=8)(x)
    spatial_out = layers.Concatenate()([layers.Lambda(lambda x: x[:, 0, :])(x),
                                        layers.Lambda(lambda x: tf.reduce_mean(x[:, 11:, :], axis=1))(x)])

    # Context Branch
    c_in = layers.Input(shape=(context_dim,))
    y = layers.BatchNormalization()(c_in)
    y = layers.Dense(32, activation='relu')(y)

    # Combined Head
    merged = layers.Concatenate()([spatial_out, y])
    z = layers.Dense(128, activation='gelu', kernel_regularizer=regularizers.l2(1e-4))(merged)
    z = layers.Dropout(0.5)(z)
    out = layers.Dense(1, activation='sigmoid')(z)

    model = models.Model(inputs=[s_in, c_in], outputs=out)
    model.compile(optimizer=tf.keras.optimizers.Adam(3e-5), loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC(name='auc')])
    return model

# 1. Load Data
df = pd.read_csv('/content/drive/MyDrive/train.csv', low_memory=False)
numeric_cols = ['X', 'Y', 'S', 'A', 'Dir', 'YardLine', 'Distance', 'HomeScoreBeforePlay', 'VisitorScoreBeforePlay', 'DefendersInTheBox']
for col in numeric_cols: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

# 2. Process
Xs, Xc, Y, meta = build_hybrid_tensors(df)
Xc_scaled = StandardScaler().fit_transform(Xc)
(Xs_train, Xs_val, Xc_train, Xc_val, y_train, y_val, m_train, m_val) = train_test_split(
    Xs, Xc_scaled, Y, meta, test_size=0.2, random_state=42, stratify=Y
)

# 3. Generator
def get_dataset(xs, xc, y, batch_size=32):
    i0, i1 = np.where(y == 0)[0], np.where(y == 1)[0]
    def gen():
        while True:
            idx = np.concatenate([np.random.choice(i0, batch_size//2), np.random.choice(i1, batch_size//2)])
            yield (xs[idx], xc[idx]), y[idx]
    return tf.data.Dataset.from_generator(gen, output_signature=((tf.TensorSpec((batch_size,22,5)), tf.TensorSpec((batch_size,5))), tf.TensorSpec((batch_size,))))

# 4. Train
model = build_hybrid_model()
history = model.fit(get_dataset(Xs_train, Xc_train, y_train),
                    steps_per_epoch=len(y_train)//32,
                    validation_data=([Xs_val, Xc_val], y_val),
                    epochs=50,
                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, restore_best_weights=True, mode='max')])

from sklearn.linear_model import LogisticRegression

# 1. CALIBRATE THE PROBABILITIES
# Raw model outputs are often 'over-confident'; we fix that here.
print("âš–ï¸ Calibrating probabilities with Platt Scaling...")
val_raw = model.predict([Xs_val, Xc_val], batch_size=32).reshape(-1, 1)
calibrator = LogisticRegression().fit(val_raw, y_val)

# 2. GENERATE GLOBAL PREDICTIONS
all_raw = model.predict([Xs, Xc_scaled], batch_size=32).reshape(-1, 1)
calibrated_probs = calibrator.predict_proba(all_raw)[:, 1]

# 3. CREATE RESULTS DATAFRAME
results = pd.DataFrame(meta, columns=['NflId', 'DisplayName'])
results['Actual_EPR'] = Y
results['Expected_EPR'] = calibrated_probs

# 4. AGGREGATE BY PLAYER
# We filter for 50+ carries to ensure statistical significance
leaderboard = results.groupby(['NflId', 'DisplayName']).agg(
    Carries=('Actual_EPR', 'count'),
    Actual_EPR=('Actual_EPR', 'mean'),
    Expected_EPR=('Expected_EPR', 'mean')
).reset_index()

leaderboard = leaderboard[leaderboard['Carries'] >= 50].copy()

# 5. CALCULATE TRUE EVA (Mean-Centered)
# This centers the "Average" player at 0.00%
league_mean_gap = (leaderboard['Actual_EPR'] - leaderboard['Expected_EPR']).mean()
leaderboard['True_EVA'] = (leaderboard['Actual_EPR'] - leaderboard['Expected_EPR']) - league_mean_gap

# 6. DISPLAY STYLED TABLE
print("\n--- FINAL NFL LEADERBOARD: EXPLOSIVE VALUE ADDED (EVA) ---")
display(leaderboard.sort_values('True_EVA', ascending=False).style.format({
    'Actual_EPR': '{:.2%}',
    'Expected_EPR': '{:.2%}',
    'True_EVA': '{:+.2%}'
}).background_gradient(cmap='RdYlGn', subset=['True_EVA']))

print("ðŸš€ Starting Optimized Ablation Study...")
scores = {}

# 1. Spatial Only - USE A LARGER BATCH SIZE
print("Training Spatial Only...")
m_s = build_spatial_only()
m_s.fit(
    Xs_train, y_train,
    epochs=5,
    batch_size=256, # 8x faster data transfer
    verbose=1       # Turn on to see progress
)
scores['Spatial Only'] = m_s.evaluate(Xs_val, y_val, batch_size=256, verbose=0)[1]

# 2. Context Only - This should be lightning fast
print("Training Context Only...")
m_c = build_context_only()
m_c.fit(
    Xc_train, y_train,
    epochs=5,
    batch_size=256,
    verbose=1
)
scores['Context Only'] = m_c.evaluate(Xc_val, y_val, batch_size=256, verbose=0)[1]

# 3. Hybrid (Already calculated)
scores['Hybrid (Spatial+Context)'] = max(history.history['val_auc'])

# --- VISUALIZATION ---
plt.figure(figsize=(12, 7))
df_ab = pd.DataFrame(list(scores.items()), columns=['Model Architecture', 'AUC Score'])
df_ab = df_ab.sort_values('AUC Score', ascending=True)

colors = ['#636EFA', '#EF553B', '#00CC96'] # Distinct colors for each tier
ax = sns.barplot(x='AUC Score', y='Model Architecture', data=df_ab, palette=colors)

plt.title("Ablation Study: Breaking the 0.70 AUC Ceiling", fontsize=15, pad=20)
plt.xlim(0.5, 0.75)
plt.grid(axis='x', linestyle='--', alpha=0.7)

# Add value labels to the bars
for i, v in enumerate(df_ab['AUC Score']):
    ax.text(v + 0.005, i, f"{v:.4f}", color='black', va='center', fontweight='bold', fontsize=12)

plt.tight_layout()
plt.show()